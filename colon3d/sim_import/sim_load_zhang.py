from pathlib import Path

import numpy as np

from colon3d.util.general_util import find_between_str
from colon3d.util.rotations_util import normalize_quaternions
from colon3d.util.torch_util import np_func

# --------------------------------------------------------------------------------------------------------------------


def load_sim_raw(
    input_data_path: Path,
    limit_n_scenes: int,
    limit_n_frames: int,
    fps_override: float,
    cam_to_load: str,
):
    """extract the data from the cases folders generated by the Zhang22 simulator"""
    cases_paths = [p for p in input_data_path.glob("Case*") if p.is_dir()]
    cases_paths.sort()
    cases_paths = cases_paths[:limit_n_scenes]
    scenes_names = []  # list of scene names
    rgb_frames_paths_per_scene = []  # list of lists
    cam_poses_per_scene = []
    metadata_per_scene = []  # list of metadata per scene

    for scene_path in cases_paths:
        scenes_names.append(scene_path.name)
        rgb_frames_paths = list(scene_path / cam_to_load.glob("*.png"))
        rgb_frames_paths.sort()
        rgb_frames_paths = rgb_frames_paths[:limit_n_frames]
        assert len(rgb_frames_paths) > 0, f"no RGB frames found in {scene_path}"
        metadata_per_scene.append(get_scene_metadata(fps_override))
        rgb_frames_paths_per_scene.append(rgb_frames_paths)
        cam_poses_per_scene.append(
            get_cam_poses(scene_path=scene_path, limit_n_frames=limit_n_frames, cam_to_load=cam_to_load),
        )
        
    return (
        scenes_names,
        metadata_per_scene,
        rgb_frames_paths_per_scene,
        cam_poses_per_scene,
    )


# --------------------------------------------------------------------------------------------------------------------


def get_scene_metadata(fps_override) -> dict:
    # The values are based on https://github.com/zsustc/colon_reconstruction_dataset
    focal_length_mm = 4.969783  # [mm]
    total_sensor_size_x_mm = 10.26  # [mm]
    total_sensor_size_y_mm = 7.695  # [mm]
    frame_width = 480  # [pixels]
    frame_height = 640  # [pixels]
    min_vis_z_mm = 0  # [mm] not relevant for this simulator
    frame_time_interval = 1 / 20  # [sec]

    fps = 1 / frame_time_interval  # [Hz]
    if fps_override != 0:
        fps = fps_override

    # per-pixel sensor size
    sx = total_sensor_size_x_mm / frame_width  # [millimeter/pixel]
    sy = total_sensor_size_y_mm / frame_height  # [millimeter/pixel]
    # focal-length in pixel units
    fx = focal_length_mm / sx
    fy = focal_length_mm / sy
    # the optical center pixel location
    cx = frame_width / 2
    cy = frame_height / 2
    metadata = {
        "frame_width": frame_width,  # [pixels]
        "frame_height": frame_height,  # [pixels]
        "fx": float(fx),  # focal length in x-axis [pixels]
        "fy": float(fy),  # focal length in y-axis [pixels]
        "cx": cx,  # optical center in x-axis [pixels]
        "cy": cy,  # optical center in y-axis [pixels]
        "fps": fps,  # frame rate [Hz]
        "distort_pram": None,  # simulated images are not distorted
        "min_vis_z_mm": min_vis_z_mm,  # in the simulation,
        "sim_info": {
            "total_sensor_size_x_mm": total_sensor_size_x_mm,
            "total_sensor_size_y_mm": total_sensor_size_y_mm,
            "focal_length_mm": float(focal_length_mm),
        },
    }

    return metadata


# --------------------------------------------------------------------------------------------------------------------
def get_cam_poses(scene_path: Path, limit_n_frames: int, cam_to_load: str) -> np.ndarray:
    cam_name_letter = "L" if cam_to_load.name == "Left" else "R"
    pos_file_path = next(scene_path.glob(scene_path / f"_Camera Position {cam_name_letter} Data.txt"))
    i = 0
    pos_x = []
    pos_y = []
    pos_z = []
    loaded_translation_to_mm = 10  # multiply the loaded translation values by this factor to get mm units.
    # (based on the readme of https://github.com/zsustc/colon_reconstruction_dataset)

    with pos_file_path.open() as file:
        lines = file.readlines()
        for line in lines:
            frame_ind = int(find_between_str(line, "Frame ", " "))
            assert i == frame_ind
            pos_x.append(loaded_translation_to_mm * float(find_between_str(line, "X=", ",")))
            pos_y.append(loaded_translation_to_mm * float(find_between_str(line, "Y=", ",")))
            pos_z.append(loaded_translation_to_mm * float(find_between_str(line, "Z=", " ")))
            i += 1
            if i == limit_n_frames:
                break
    rot_file_path = next(scene_path.glob(scene_path / f"_Camera Position {cam_name_letter} Data.txt"))
    i = 0
    quat_x = []
    quat_y = []
    quat_z = []
    quat_w = []
    with rot_file_path.open() as file:
        lines = file.readlines()
        for line in lines:
            frame_ind = int(find_between_str(line, "Frame ", " "))
            assert i == frame_ind
            quat_x.append(float(find_between_str(line, "X=", ",")))
            quat_y.append(float(find_between_str(line, "Y=", ",")))
            quat_z.append(float(find_between_str(line, "Z=", ",")))
            quat_w.append(float(find_between_str(line, "W=", " ")))
            i += 1
            if i == limit_n_frames:
                break
    # save the 6-DOF camera poses in the world coordinates as a numpy array with shape (N, 7) where N is the number of frames
    # the 7 values are: x, y, z, q_w, q_x, q_y, q_z
    # the world coordinate system is defined by the camera coordinate system at the first frame (the optical axis of the camera is the z-axis)
    # (x, y, z) is the camera position in the world system (in mm)
    cam_loc = np.column_stack((pos_x, pos_y, pos_z))
    # (q_w, q_x, q_y, q_z) is a  unit-quaternion has the real part as the first value, that represents the camera rotation w.r.t. the world system
    cam_rot = np.column_stack((quat_w, quat_x, quat_y, quat_z))
    # transform from the unity left handed space to a right handed space  (see readme.md of https://github.com/zsustc/colon_reconstruction_dataset)
    # [x,-y,z]-->[x,y,z]
    cam_loc[:, 1] *= -1
    #  [qw, qx, qy, qz]-->[ qw, -qx, qy, -qz]
    cam_rot[:, 1] *= -1
    cam_rot[:, 3] *= -1
    cam_rot = np_func(normalize_quaternions)(cam_rot)
    cam_poses = np.column_stack((cam_loc, cam_rot))
    return cam_poses


# --------------------------------------------------------------------------------------------------------------------
